{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "def remove_pattern(row_content):\n",
    "    return re.sub(r'[?|$|.|!]',r'', row_content)\n",
    "def tokenize(row_content):\n",
    "    return ViTokenizer.tokenize(row_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  Sentiment                                            Content\n",
      "0      0          1  Khung_cảnh đặc_trưng chưa bị pha_tạp Có nhiều ...\n",
      "1      1          1  Tôi có dịp vào Gia_lai công_tác , sau ngày làm...\n",
      "2      2          1  Biển đẹp , buổi tối ở bãi biển rất tấp_nập , q...\n",
      "3      3          0           hải_sản ko phong_phú và chế_biến ko ngon\n",
      "4      4          1  Tôi đến Hội_An khoảng 20 lần , lần nào cũng và...\n",
      "5      5          1  Chùa trên núi cao , rất mát_mẻ Chùa quả là hoà...\n",
      "6      6          1  Tôi có đến Dinh_III , ấn_tượng với các hiện_vậ...\n",
      "7      7          1  Nếu mục_đích của bạn đến Bangkok là để mua_sắm...\n",
      "8      9          1  Đây là 1 khách_sạn chứ không phải resort nhưng...\n",
      "9     10          1  Nhà_thờ nằm ngay khu_vực trung_tâm , nhưng có ...\n",
      "10    11          1  Chùa rộng , nằm trên đồi cao , tách_biệt khu d...\n",
      "11    12          0  Bãi biển Cha_Am không phẳng , bãi cát không mị...\n",
      "12    13          0  Ngay gần Rừng_Quốc_gia Ba Vì , không_gian rất ...\n",
      "13    14          1  Bảo_tàng được bài_trí công_phu , chia thành cá...\n",
      "14    15          1  Mình đã qua chợ mua một_số quà cho bạn_bè trướ...\n",
      "15    16          1  Đầu năm tôi có đi Yên_tử , lúc xuống có vào Th...\n",
      "16    17          1  Đầu xuân những năm gần đây nhà tôi hay đi chơi...\n",
      "17    18          0  Tôi đã đến thánh_địa Mỹ_sơn , lúc đầu tôi hình...\n",
      "18    19          1  Rất nên đi , cảm_giác đi thuyền trên sông , và...\n",
      "19    20          1  Làng nằm cách trung_tâm Hà_Nội chưa tới 50km ,...\n",
      "20    21          0  Không_gian chùa khá hẹp , chắc do nằm ngay khu...\n",
      "21    22          1  Nhà_ga rất nhỏ nhưng cũng là duyên_dáng nhất m...\n",
      "22    23          0  Chợ đêm này bình_thường , không có hoạt_động h...\n",
      "23    24          1  Ga xe lửa nhỏ xinh , đẹp như trong truyện_cổ_t...\n",
      "24    25          1  Không nên bỏ lỡ dịp tới thăm chợ đêm Cicada Ch...\n",
      "25    26          0  Trừ dịp có sự_kiện thì cũng hay , còn ngày thư...\n",
      "26    27          1  Chùa rất cổ , chùa nằm trên đỉnh đồi , lên chù...\n",
      "27    28          0  Theo mình nghĩ thì mọi người chủ_yếu đến đây đ...\n",
      "28    29          0  Hôm tự thuê xe_tuk - tuk đi chơi Angkor , buổi...\n",
      "29    30          1  Ở Lotte này tôi mới trải nghiệm Sky walk vào m...\n",
      "..   ...        ...                                                ...\n",
      "120  124          1  Nhà_thờ đá nằm ở ngay trung_tâm Sapa , tiện ch...\n",
      "121  125          1  Phải nói thật là đi cả Cô Tô và Thanh_Lân sẽ d...\n",
      "122  126          0  chỉ đi trên thuyền là cảm_thấy thư_thái , còn ...\n",
      "123  127          0  Đảo Cô Tô rất đông người đến du_lịch cho_nên m...\n",
      "124  128          1  Nước biển rất mát , trong như gương Đặc_biệt d...\n",
      "125  129          1  Bãi biển sạch đẹp cho cả việc chụp ảnh và tắm ...\n",
      "126  130          1  Resort gần biển , có view nhìn ra biển , vị_tr...\n",
      "127  131          1  Cảnh đẹp , nếu bạn và gia_đình đi nghỉ thì 2 n...\n",
      "128  132          1  Phía trong thành rất yên_tĩnh , nhiều cây_cối ...\n",
      "129  133          0  Nghe bạn giới_thiệu lên Sapa phải thử , nhưng ...\n",
      "130  134          1  Biển tương_đối êm , nước trong , dễ_dàng vui_c...\n",
      "131  135          1  Nhiều cảm_xúc ùa về khi tới tham_quan , khó có...\n",
      "132  136          1  Chợ đêm bán rất nhiều thứ Mà_ăn lại ngon nữa N...\n",
      "133  137          0  Ở đây đi chụp ảnh thì được chứ nếu để đi du_lị...\n",
      "134  138          1  Khách_sạn có 26 phòng tiện_nghi sang_trọng nằm...\n",
      "135  139          1  Bạn nên đến đây khi Bình_Ba còn chưa bị thương...\n",
      "136  140          1  Cũng giống như bao bãi biển khác như Sầm_Sơn ,...\n",
      "137  141          1  Resort chỉ đạt mức 3 sao , có_thể do được xây_...\n",
      "138  142          1  Vào trong thì rất mát Ở trong rất đẹp Rất nhiề...\n",
      "139  143          1  Khi bước vào bảo_tàng cảm_giác sẽ ngỡ_ngàng vì...\n",
      "140  144          1  Chùa rất cổ_kính , đẹp , yên_tĩnh Đi từ Hà_Nội...\n",
      "141  145          1  Vincom_Bà_Triệu gồm các phân khu chức_năng rộn...\n",
      "142  146          1  Người Hà_Nội đã quen_thuộc với hoạt_động chợ đ...\n",
      "143  147          1  Đến Bangkok mà không ghé thăm khu chợ_trời Cha...\n",
      "144  148          1  Đây có_thể là đoạn đường đèo trải nhựa dài nhấ...\n",
      "145  149          0  Hôm trước đưa cả công_ty đi Chùa_Hương và ghé ...\n",
      "146  150          1  Về với Nha_Trang , bạn cần mùa những sản_phẩm ...\n",
      "147  151          1  Nhà_mình đã đến tham_quan vườn thú mở Khao_Khe...\n",
      "148  152          1  Chợ có đủ loại mặt_hàng với giá_cả vừa túi_tiề...\n",
      "149  153          1  Hay nhất trong khu này là có vườn sim , nếu đi...\n",
      "\n",
      "[150 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import re\n",
    "df = pandas.read_csv('train.txt', sep='\\t')\n",
    "# print(df)\n",
    "df[\"Content\"] = df[\"Content\"].apply(remove_pattern)\n",
    "df[\"Content\"]= df[\"Content\"].apply(tokenize)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(max_df=0.95)\n",
    "x = v.fit_transform(df['Content']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 1852)\n"
     ]
    }
   ],
   "source": [
    "# print(v.get_feature_names())\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Content'], df['Sentiment'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = GaussianNB().fit(X_train_tfidf.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(count_vect.transform([ViTokenizer.tokenize(\"Chùa cổ kính, đẹp\")]).toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trường đại_học bách_khoa hà_nội\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
